name: mpt-7b-finetuned

# Deployment configuration
gpu_num: 1  # Number of GPUs to use
cluster: REPLACE_WITH_YOUR_CLUSTER # Name of the cluster to use for this run
gpu_type: a10 # Type of GPU to use.
replicas: 1 # Number of replicas to use for this run


integrations:
# Clone and install the examples repo so we can use the deployment helper from it
- integration_type: git_repo
  git_repo: dakinggg/examples
  ssh_clone: false
  # git_commit: c92d827ebf76dd0a52bcec1ed63c0bab3730764e
  git_branch: fqa2

# Add the examples folder to the PYTHONPATH so we can import the deployment helper
# Install composer to use the cloud download helper
command: |
  export PYTHONPATH=$PYTHONPATH:/code/examples
  pip uninstall packaging -y
  rm /usr/lib/python3/dist-packages/packaging-23.1.dist-info/REQUESTED
  pip install composer[streaming,libcloud,oci]==0.14.1
  pip install packaging==23.1

model:
  # Specify how to download the model from object store
  downloader: examples.end-to-end-examples.sec_10k_qa.deployment_download_helper.download_model
  download_parameters:
    remote_uri: OBJECT_STORE://BUCKET_NAME/sec_10k_demo/checkpoints/mpt-7b-hf/
  model_handler: examples.inference-deployments.mpt.mpt_7b_handler.MPTModelHandler # Use the provided MPT handler
  model_parameters:
    model_name: /downloaded_hf_checkpoint/ # Path is hardcoded in deployment_download_helper.download_model

image: mosaicml/inference:0.0.93 # Use the Docker image provided by MosaicML
